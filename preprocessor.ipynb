{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "844411bc-c17e-444c-a399-940f8ae671e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature generation...\n",
      " Loading data...\n",
      "(72,)\n",
      " All features generated and saved to: data/ES_preprocessed_all_features_training_zeros_corrected.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define input features and categorical encodings\n",
    "INPUT_FEATURES = [\n",
    "    'Open', 'High', 'Low', 'Close', 'RSI', 'MACD', 'HABodyRangeRatio', 'MyWAZLTTrend',\n",
    "    'MACDState', 'HAColor', 'HALongWick', 'HAGreenConsec', 'HARedConsec', 'EMAState',\n",
    "    'HAHighToEMALong', 'HACloseToEMALong', 'HALowToEMALong',\n",
    "    'HAHighToEMAShort', 'HACloseToEMAShort', 'HALowToEMAShort'\n",
    "]\n",
    "\n",
    "CATEGORICAL_RANGES = {\n",
    "    'MACDState': list(range(1, 17)),\n",
    "    'HAColor': [1, 2, 3],\n",
    "    'HALongWick': [1, 2, 3],\n",
    "    'HAGreenConsec': list(range(0, 51)),\n",
    "    'HARedConsec': list(range(0, 51)),\n",
    "    'EMAState': list(range(1, 17)),\n",
    "    'HAHighToEMALong': [1, 2, 3],\n",
    "    'HACloseToEMALong': [1, 2, 3],\n",
    "    'HALowToEMALong': [1, 2, 3],\n",
    "    'HAHighToEMAShort': [1, 2, 3],\n",
    "    'HACloseToEMAShort': [1, 2, 3],\n",
    "    'HALowToEMAShort': [1, 2, 3]\n",
    "}\n",
    "\n",
    "def generate_all_features(input_file: str, output_csv: str):\n",
    "    print(\" Loading data...\")\n",
    "\n",
    "    # Load from XLSX\n",
    "    df = pd.read_excel(input_file)\n",
    "\n",
    "    required_cols = ['Date'] + INPUT_FEATURES\n",
    "    missing = [col for col in required_cols if col not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns in input file: {missing}\")\n",
    "#     print(df.head())\n",
    "    \n",
    "    \n",
    "    df['Time'] = df['Date'].dt.time\n",
    "    \n",
    "    df = df[df['Time'].apply(lambda x: pd.Timestamp('08:35:00').time() <= x <= pd.Timestamp('10:25:00').time())]\n",
    "    \n",
    "    # Drop Time column if no longer needed\n",
    "    df.drop(columns=['Time'], inplace=True)\n",
    "    \n",
    "    \n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['DayOnly'] = df['Date'].dt.date  # For grouping\n",
    "    \n",
    "    print(np.unique(df[\"DayOnly\"]).shape)\n",
    "    \n",
    "    # Lag Continuous Features\n",
    "    for col in INPUT_FEATURES:\n",
    "        if col in CATEGORICAL_RANGES:\n",
    "            continue  # Categorical handled separately\n",
    "        df[f\"{col}_lag1\"] = df.groupby('DayOnly')[col].shift(1).fillna(0)\n",
    "\n",
    "    #  Lag Categorical Features BEFORE dropping\n",
    "    for col, cats in CATEGORICAL_RANGES.items():\n",
    "        lag_col = f\"{col}_lag1\"\n",
    "        df[lag_col] = df.groupby('DayOnly')[col].shift(1).fillna(0)\n",
    "\n",
    "    # One-hot encode categorical columns and their lag versions\n",
    "    for col, cats in CATEGORICAL_RANGES.items():\n",
    "        # One-hot current\n",
    "        df[col] = pd.Categorical(df[col], categories=cats)\n",
    "        dummies = pd.get_dummies(df[col], prefix=col)\n",
    "        df = pd.concat([df.drop(columns=[col]), dummies], axis=1)\n",
    "\n",
    "        # One-hot lagged\n",
    "        lag_col = f\"{col}_lag1\"\n",
    "        df[lag_col] = pd.Categorical(df[lag_col], categories=cats)\n",
    "        dummies_lag = pd.get_dummies(df[lag_col], prefix=lag_col)\n",
    "        df = pd.concat([df.drop(columns=[lag_col]), dummies_lag], axis=1)\n",
    "\n",
    "    # Drop helper column\n",
    "    df.drop(columns=['DayOnly'], inplace=True)\n",
    "\n",
    "    #  Ensure Date is first column\n",
    "    cols = list(df.columns)\n",
    "    cols.insert(0, cols.pop(cols.index('Date')))\n",
    "    df = df[cols]\n",
    "\n",
    "    # Save\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\" All features generated and saved to: {output_csv}\")\n",
    "\n",
    "# Main block to run directly\n",
    "if __name__ == \"__main__\":\n",
    "    input_xlsx = 'data/concat_ESData.xlsx'  # Change path as needed\n",
    "    output_dir = 'data/'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_csv = os.path.join(output_dir, \"ES_preprocessed_all_features_training_zeros_corrected.csv\")\n",
    "   \n",
    "    print(\"Starting feature generation...\")\n",
    "    generate_all_features(input_xlsx, output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00fd4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Main block to run directly\n",
    "# if __name__ == \"__main__\":\n",
    "#     input_xlsx = 'data/concat_ESData.xlsx'  # Change path as needed\n",
    "#     output_dir = 'data/'\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "#     output_csv = os.path.join(output_dir, \"ES_preprocessed_all_features_training_zeros_v1.csv\")\n",
    "   \n",
    "#     print(\"Starting feature generation...\")\n",
    "#     generate_all_features(input_xlsx, output_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
